Обзор методов кластеризации на 2012 год [A Survey of Text Clustering Algorithms](zotero://select/library/items/4TGEIG5D)
## Ансамбль моделей
Для кластеризации может быть применен ансамбль моделей. Результат кластеризации получается через консенсус 
- [A New Approach of Categorizing Text Documents through Consensus Clustering](zotero://select/library/items/ZPM4F95S),
- [Integration of cluster ensemble and EM based text mining for microarray gene cluster identification and annotation](zotero://select/library/items/PXDY98P6)

Консенсус может быть применен не только к разным моделям кластеризации, но и к разным данным. Так, можно объединить текстовые данные и данные о ссылках между текстами  [Effective and Efficient Spectral Clustering on Text and Link Data](zotero://select/library/items/VEX4S7IS)

Можно использовать пересечение результатов нескольких классификаторов в качестве обучающего набора данных и на его основе подготовить классификатор для определения классов остальных документов [An ensemble approach for text document clustering using Wikipedia concepts](zotero://select/library/items/3GGETNTP) 

# Бикластеризация

Бикластеризация это когда TermDocumentMatrix кластеризуют и по строкам и по столбцам одновременно.

Можно делить вектор признаков на подмножества и запускать кластеризацию по-отдельности [Ensemble Block Co-clustering](zotero://select/library/items/EISUUNEJ)

Еще одна непонятная статья про бикластеризацию [Regularized Dual-PPMI Co-clustering for Text Data](zotero://select/library/items/PKMVMQ6L)

## Инкрементальный алгоритм
Для того, чтобы алгоритм мог обрабатывать данные в онлайн-режиме его нужно сделать инкрементальным [Incremental hierarchical clustering of text documents](zotero://select/library/items/BZWB2NEF)

Для инкрементальной кластеризации может использоваться алгоритм FGSDMM+ [A Text Clustering Algorithm Using an Online Clustering Scheme for Initialization](zotero://select/library/items/6AZA9Q35)

## Прочие алгоритмы
Для кластеризации ключевых слов построили граф минимальных джакардовых расстояний и выделеили связные подграфы [Graph Clustering for Large-Scale Text-Mining of Brain Imaging Studies](zotero://select/library/items/QJ4PG3XJ)

Можно понизить размеррность пространсва признаков методом PLSA и найти кластеры по расстоянию до полученных векторов [Text Document Latent Subspace Clustering by PLSA Factors](zotero://select/library/items/WQLPX6FA)

## Кластеризация наполовину с учителем
В статье описали как кластеризация применяется в классфиикации и предложили semi-supervised алгоритм кластерищации [The impact of semi-supervised clustering on text classification](zotero://select/library/items/RHG2KATD)

## Используемые признаки
Извлечение именнованных сущностей не улучшает результат кластеризации [Named entities as privileged information for hierarchical text clustering](zotero://select/library/items/KRILKFE9)

Текст может быть представлен не только в форме слов и n-gramm, но и вероятностями переходов в марковских цепях [A new text representation method for clustering based on higher order Markov model](zotero://select/library/items/MSJ2Q4NF)

Можно сократить размер текста, оставив только частые цепочки слов [Text document clustering based on frequent word sequences](zotero://select/library/items/PZDXUVGZ)

Можно сократить размерность VSM отобрав значимые признаки метрикой HFSM [Text Document Clustering with Hybrid Feature Selection](zotero://select/library/items/C6QBREWN)